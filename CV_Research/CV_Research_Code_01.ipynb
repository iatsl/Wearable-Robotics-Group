{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Glr-lDSXcGmW"
   },
   "source": [
    "Import PyTorch and other Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zAa-ix9sTWV3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4496/3501874552.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# import PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sYwYLGSiTlW7"
   },
   "outputs": [],
   "source": [
    "#import other packages\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6EvNuUCcNFt"
   },
   "source": [
    "Load ExoNet Image Dataset and the labels from the Dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_4496/1006074814.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\akurb\\AppData\\Local\\Temp/ipykernel_4496/1006074814.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    install google\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "install google\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dQyJ7LbpTzZ0"
   },
   "outputs": [],
   "source": [
    "#Load Images from Dropbox\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import shutil\n",
    "\n",
    "\n",
    "images_url = 'https://www.dropbox.com/s/30wjsbnrv039df5/ExoNet_Test.zip?dl=1'\n",
    "db_username = 'agzkurbis@uwaterloo.ca'\n",
    "db_password = 'Temppassword123!'\n",
    "\n",
    "downloaded_file = requests.get(images_url, auth=HTTPBasicAuth(db_username, db_password))\n",
    "\n",
    "# dest_file = open('/Users/aj/Desktop/test.jpg', 'w+')\n",
    "\n",
    "# dest_file.write(downloaded_file.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! copy \"D:\\\\UofT_Project\\\\CV_Research_Code_02\\\\Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "filename = 'D:\\\\UofT_Project\\\\CV_Research_Code_02\\\\ExoNet_Test.zip'\n",
    "extract_dir = \"D:\\\\UofT_Project\\\\CV_Research_Code_02\\\\Dataset\"\n",
    "shutil.unpack_archive(filename, extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vh-BgNZGVX42"
   },
   "outputs": [],
   "source": [
    "#Load ExoNet labels from Dropbox\n",
    "# https://www.dropbox.com/s/ksodxkpxzcmtspu/Labels.csv?dl=0\n",
    "\n",
    "labels_url = 'https://www.dropbox.com/s/ksodxkpxzcmtspu/Labels.csv?dl=1'\n",
    "db_username = 'agzkurbis@uwaterloo.ca'\n",
    "db_password = 'Temppassword123!'\n",
    "\n",
    "downloaded_file = requests.get(labels_url, auth=HTTPBasicAuth(db_username, db_password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjdVhkXbcV8D"
   },
   "source": [
    "Sort Images into training/validation/testing \n",
    "this split should be as follows:\n",
    "- 89.5% Training\n",
    "- 3.5% Validation \n",
    "- 7% Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZO07RhCkkz9m"
   },
   "outputs": [],
   "source": [
    "#Creating a definition for randomized dataset creation\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.895, validate_percent=.035, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "T9a0wwp0XxUD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akurb\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akurb\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akurb\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>LG-T-IS/['IMG_01_1'] frame 52116.jpg</td>\n",
       "      <td>LG-T-IS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>LG-S/['IMG_01_1'] frame 2070.jpg</td>\n",
       "      <td>LG-S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>IS-T-DW/['IMG_01_1'] frame 16614.jpg</td>\n",
       "      <td>IS-T-DW</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>LG-T-O/['IMG_01_1'] frame 6774.jpg</td>\n",
       "      <td>LG-T-O</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>IS-S/['IMG_01_1'] frame 46788.jpg</td>\n",
       "      <td>IS-S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename category    set\n",
       "983   LG-T-IS/['IMG_01_1'] frame 52116.jpg  LG-T-IS  train\n",
       "676       LG-S/['IMG_01_1'] frame 2070.jpg     LG-S  train\n",
       "400   IS-T-DW/['IMG_01_1'] frame 16614.jpg  IS-T-DW  train\n",
       "1096    LG-T-O/['IMG_01_1'] frame 6774.jpg   LG-T-O  train\n",
       "398      IS-S/['IMG_01_1'] frame 46788.jpg     IS-S  train"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomize Images and split into Training/Validation/Testing\n",
    "\n",
    "#load directory df\n",
    "IMG_DIR = \"D:\\\\UofT_Project\\\\CV_Research_Code_02\\\\Dataset\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for fold in os.listdir(IMG_DIR):\n",
    "    for filename in os.listdir(f'{IMG_DIR}/{fold}'):\n",
    "        dataset.append((f'{fold}/{filename}', fold))\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=['filename', 'category'])\n",
    "\n",
    "\n",
    "df_train, df_validation, df_test = train_validate_test_split(df, train_percent=.895, validate_percent=.035)\n",
    "\n",
    "df_train['set'] = 'train'\n",
    "df_validation['set'] = 'validation'\n",
    "df_test['set'] = 'test'\n",
    "\n",
    "#what does this do? Needs to be updated to include validation labels as well \n",
    "df = df_train.append(df_validation)\n",
    "df = df_train.append(df_test)\n",
    "df.to_csv('dataset.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0b36Em40ngK"
   },
   "source": [
    "Do we need to reset the index and drop images? (skip this for now as discussed in previous meeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "coLYM8WM0mSX"
   },
   "outputs": [],
   "source": [
    "#reset index and drop images\n",
    "train_df = df[df.set == 'train'].reset_index(drop=True)\n",
    "validate_df = df[df.set == 'validation'].reset_index(drop=True)\n",
    "test_df = df[df.set == 'test'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z20jX0Jp1MEI"
   },
   "source": [
    "Resize/formate images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4he5SqGb1RGK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4496/1704469551.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#formating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "#define dementions of the images we are using (this value will need to be adjusted)\n",
    "img_width, img_height = 224, 224\n",
    "IMAGE_SIZE = (img_width, img_height)\n",
    "\n",
    "#formating \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6UoTnAQ1jrg"
   },
   "source": [
    "Initializing MobileNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cghf4_AvU10t"
   },
   "outputs": [],
   "source": [
    "#Initialize MobileNetV2 Model\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNfaTwlw1nUt"
   },
   "outputs": [],
   "source": [
    "#Defining Parameters\n",
    "#needs to be updated for torch (see thesis code)\n",
    "model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 1), \n",
    "    alpha=0.5,\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    pooling=max,\n",
    "    classes=4\n",
    ")\n",
    "\n",
    "output = model.output\n",
    "\n",
    "#Look into parameter adjustment using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNr1rIHM1vs1"
   },
   "outputs": [],
   "source": [
    "#Select optimizer, loss type, and metrics (see thesis)\n",
    "#compile the model\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M4omWTO2C4n"
   },
   "outputs": [],
   "source": [
    "#Do we need this?\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrmVqtgA2NyQ"
   },
   "outputs": [],
   "source": [
    "#save the Model Weights for MobileNetV2 to \"______\"\n",
    "\n",
    "#determine the best location for this? maybe use OneDrive since we are using Azure\n",
    "#I looked into dropbox and this seems difficult to save directly to dropbox. Might be better through a google drive, onedrive, ext.\n",
    "\n",
    "#research/update parameters here\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint('/content/gdrive/My Drive/552-project/service_weights.h5', \n",
    "                    monitor='acc', verbose=1, save_best_only=True, mode='max'),\n",
    "        ReduceLROnPlateau(monitor='acc', \n",
    "                                            patience=1, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0JKbtCU5Z97"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    IMG_DIR, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    IMG_DIR,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    IMG_DIR,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#for initial train/validation\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator, \n",
    "    steps_per_epoch=9,\n",
    "    verbose=1,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqfA2d4M53jU"
   },
   "outputs": [],
   "source": [
    "output = model.output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAreoRcgHDVG"
   },
   "source": [
    "Creating the Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBnqj6e76C4N"
   },
   "outputs": [],
   "source": [
    "#update\n",
    "num_of_test_samples= test_datagen.length\n",
    "\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, num_of_test_samples // BATCH_SIZE+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['LG', 'LG_IS', 'IS','IS_LG', 'DS_LG', 'LS_DS']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0084qI3GvgG"
   },
   "outputs": [],
   "source": [
    "#print the confusion matrix\n",
    "print(confusion_matrix(validate_df.category, validate_df.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGflTgoWHPcV"
   },
   "outputs": [],
   "source": [
    "#creating a plot for the accuracy vs epoch \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.ylabel('training loss (error)')\n",
    "plt.xlabel('# of epochs')\n",
    "plt.title('training')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.ylabel('training accuracy')\n",
    "plt.xlabel('# of epochs')\n",
    "plt.title('training')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy9UIBXhHfPG"
   },
   "outputs": [],
   "source": [
    "#Code to save the model\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "#update location\n",
    "model.save('/content/gdrive/My Drive/CV_Research/model_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msp9-vr0Hgwf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CV_Research_Code_Outline_01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
