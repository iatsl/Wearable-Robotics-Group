{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nHCP2SDZLNQ"
      },
      "source": [
        "# Final code for ICORR Project 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4TjleT_ZWSm"
      },
      "source": [
        "### Import calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU-cznD5GeNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1fb95e-c5fc-4d63-df81-347524b7fb5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import math, re, os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiG-8E6PGeNS"
      },
      "source": [
        "# TPU or GPU detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRxhyKQgGeNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f57237-0d6b-4a9a-cd1c-27a4536d8de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.105.9.98:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.105.9.98:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of accelerators:  8\n"
          ]
        }
      ],
      "source": [
        "# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\n",
        "\n",
        "try: # detect TPUs\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError: # detect GPUs\n",
        "    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfFTk4xNW-Xx"
      },
      "source": [
        "# Mount Drive to save models and figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6O4W0-QW4-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febeedfc-5a0f-4545-84fd-f7a90450eeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3YUuvvVGeNU"
      },
      "source": [
        "# Competition data access\n",
        "TPUs read data directly from Google Cloud Storage (GCS). This Kaggle utility will copy the dataset to a GCS bucket co-located with the TPU. If you have multiple datasets attached to the notebook, you can pass the name of a specific dataset to the get_gcs_path function. The name of the dataset is the name of the directory it is mounted in. Use `!ls /kaggle/input/` to list attached datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wwek7nIGzid"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP4uXfI6G09O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0720b34-7bb4-457b-9a1c-aec059acd044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [stairnet] or it does not exist.\n",
            "Are you sure you wish to set property [core/project] to stairnet?\n",
            "\n",
            "Do you want to continue (Y/n)?  y\n",
            "\n",
            "Updated property [core/project].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n"
          ]
        }
      ],
      "source": [
        "project_id = 'stairnet'\n",
        "!gcloud config set project {project_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Ecrc5VG1k6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0864e1ee-893e-4e24-fc86-ad01cccccd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 gs://stairnet_bucket/Full_StairNet_TFRecord/\n",
            "                                 gs://stairnet_bucket/Split_StairNet_TFRecord/\n",
            "                                 gs://stairnet_bucket/StairNet/\n"
          ]
        }
      ],
      "source": [
        "# Test to see if dataset location is correct\n",
        "! gsutil ls -al gs://stairnet_bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDql7S3lGeNU"
      },
      "outputs": [],
      "source": [
        "GCS_DS_PATH = 'gs://stairnet_bucket'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOjWrL49GeNV"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MXUOrEcGeNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c065c4-8d03-403e-a4bc-5fc85ad8006c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://stairnet_bucket/Split_StairNet_TFRecord\n"
          ]
        }
      ],
      "source": [
        "# Load the initial image size of 256x256\n",
        "# This a random crop of 224x224 will be taken from this later\n",
        "\n",
        "IMAGE_SIZE = [256, 256] \n",
        "\n",
        "# set the number of epochs for the run                        \n",
        "EPOCHS = 60\n",
        "\n",
        "# set the initial learning rate\n",
        "BASE_LR = 0.00001\n",
        "\n",
        "# 8 TPU cores, so 16 will be 128\n",
        "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
        "\n",
        "#To study the effect of transfer training:\n",
        "FINE_TUNE_BUFFER = 5\n",
        "\n",
        "#Change Droprate \n",
        "DROPOUT_VALUE = 0.2\n",
        "\n",
        "# For hyperparameter optimization set to 144 \n",
        "# For final run set to 'None'\n",
        "SEED_NUMBER = 144 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "GCS_PATH_SELECT = { # available image sizes\n",
        "    256: GCS_DS_PATH + '/Split_StairNet_TFRecord',\n",
        "}\n",
        "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
        "print(GCS_PATH)\n",
        "\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') # predictions on this dataset should be submitted for the competition\n",
        "\n",
        "CLASSES = ['IS', 'IS-LG', 'LG', 'LG-IS']                                                                                                                                               # 100 - 102"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_bzeJbNIJB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8b2f81-93fe-45a9-dde2-8ee2c48989b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(len(TRAINING_FILENAMES))\n",
        "print(len(VALIDATION_FILENAMES))\n",
        "print(len(TEST_FILENAMES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkKEWwppGeNX"
      },
      "source": [
        "## Visualization utilities\n",
        "data -> pixels, nothing of much interest for the machine learning practitioner in this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDPagLeNGeNY"
      },
      "outputs": [],
      "source": [
        "# numpy and matplotlib defaults\n",
        "np.set_printoptions(threshold=15, linewidth=80)\n",
        "\n",
        "def batch_to_numpy_images_and_labels(data):\n",
        "    images, labels = data\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n",
        "        numpy_labels = [None for _ in enumerate(numpy_images)]\n",
        "    # If no labels, only image IDs, return None for labels (this is the case for test data)\n",
        "    return numpy_images, numpy_labels\n",
        "\n",
        "def title_from_label_and_target(label, correct_label):\n",
        "    if correct_label is None:\n",
        "        return CLASSES[label], True\n",
        "    correct = (label == correct_label)\n",
        "    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n",
        "                                CLASSES[correct_label] if not correct else ''), correct\n",
        "\n",
        "def display_one_image(image, title, subplot, red=False, titlesize=16):\n",
        "    plt.subplot(*subplot)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    if len(title) > 0:\n",
        "        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
        "    return (subplot[0], subplot[1], subplot[2]+1)\n",
        "    \n",
        "def display_batch_of_images(databatch, predictions=None):\n",
        "    \"\"\"This will work with:\n",
        "    display_batch_of_images(images)\n",
        "    display_batch_of_images(images, predictions)\n",
        "    display_batch_of_images((images, labels))\n",
        "    display_batch_of_images((images, labels), predictions)\n",
        "    \"\"\"\n",
        "    # data\n",
        "    images, labels = batch_to_numpy_images_and_labels(databatch)\n",
        "    if labels is None:\n",
        "        labels = [None for _ in enumerate(images)]\n",
        "        \n",
        "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n",
        "    rows = int(math.sqrt(len(images)))\n",
        "    cols = len(images)//rows\n",
        "        \n",
        "    # size and spacing\n",
        "    FIGSIZE = 13.0\n",
        "    SPACING = 0.1\n",
        "    subplot=(rows,cols,1)\n",
        "    if rows < cols:\n",
        "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
        "    else:\n",
        "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
        "    \n",
        "    # display\n",
        "    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n",
        "        title = '' if label is None else CLASSES[label]\n",
        "        correct = True\n",
        "        if predictions is not None:\n",
        "            title, correct = title_from_label_and_target(predictions[i], label)\n",
        "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n",
        "        subplot = display_one_image(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n",
        "    \n",
        "    #layout\n",
        "    plt.tight_layout()\n",
        "    if label is None and predictions is None:\n",
        "        plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    else:\n",
        "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
        "    plt.show()\n",
        "\n",
        "def display_confusion_matrix(cmat, score, precision, recall):\n",
        "    plt.figure(figsize=(15,15))\n",
        "    ax = plt.gca()\n",
        "    ax.matshow(cmat, cmap='Reds')\n",
        "    ax.set_xticks(range(len(CLASSES)))\n",
        "    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
        "    ax.set_yticks(range(len(CLASSES)))\n",
        "    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "    titlestring = \"\"\n",
        "    if score is not None:\n",
        "        titlestring += 'f1 = {:.3f} '.format(score)\n",
        "    if precision is not None:\n",
        "        titlestring += '\\nprecision = {:.3f} '.format(precision)\n",
        "    if recall is not None:\n",
        "        titlestring += '\\nrecall = {:.3f} '.format(recall)\n",
        "    if len(titlestring) > 0:\n",
        "        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n",
        "    plt.show()\n",
        "    \n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot%10==1: # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdSgBZhQGeNZ"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ljehxztGeNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffe8a87-4b15-44f3-e0fc-d7603624b9ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 461328 training images, 18039 validation images, 36085 test images\n"
          ]
        }
      ],
      "source": [
        "def decode_image(image_data):\n",
        "    image = tf.io.decode_raw(image_data, tf.uint8)\n",
        "    # image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    # image = image_data\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
        "    image = tf.image.random_crop(value=image, size=(224, 224, 3))\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"label\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    label = tf.cast(example['label'], tf.int32)\n",
        "    return image, label # returns a dataset of (image, label) pairs\n",
        "\n",
        "def read_unlabeled_tfrecord(example):\n",
        "    UNLABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"label\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    idnum = example['label']\n",
        "    return image, idnum # returns a dataset of image(s)\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset\n",
        "\n",
        "def data_augment(image, label):\n",
        "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
        "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
        "    # of the TPU while the TPU itself is computing gradients.\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    #image = tf.image.random_saturation(image, 0, 2)\n",
        "    return image, label   \n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    # for hyperparameter testing using random seed to shuffle the data the same to elimite this variable from results\n",
        "    dataset = dataset.shuffle(count_data_items(TRAINING_FILENAMES)/10, seed=SEED_NUMBER, reshuffle_each_iteration=None)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    # for hyperparameter testing using random seed to shuffle the data the same to elimite this variable from results\n",
        "    dataset = dataset.shuffle(count_data_items(VALIDATION_FILENAMES)/10, seed=SEED_NUMBER, reshuffle_each_iteration=None)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=True, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    # for hyperparameter testing using random seed to shuffle the data the same to elimite this variable from results\n",
        "    dataset = dataset.shuffle(count_data_items(TEST_FILENAMES)/10, seed=SEED_NUMBER, reshuffle_each_iteration=None)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset \n",
        "\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
        "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "VALIDATION_STEPS = -(-NUM_VALIDATION_IMAGES // BATCH_SIZE) # The \"-(-//)\" trick rounds up instead of down :-)\n",
        "TEST_STEPS = -(-NUM_TEST_IMAGES // BATCH_SIZE)             # The \"-(-//)\" trick rounds up instead of down :-)\n",
        "print('Dataset: {} training images, {} validation images, {} test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-wk6lgcZ9r3"
      },
      "source": [
        "Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtJsFDjdaANx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "799e3588-201a-4515-eae9-dfd6eaf453c8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-09138eba0484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlabel_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_training_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlabel_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2390\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2392\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Get labels and their countings\n",
        "\n",
        "def get_training_dataset_raw():\n",
        "\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True, ordered=False)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "raw_training_dataset = get_training_dataset_raw()\n",
        "\n",
        "label_counter = Counter()\n",
        "for images, labels in raw_training_dataset:\n",
        "    label_counter.update([labels.numpy()])\n",
        "\n",
        "del raw_training_dataset    \n",
        "    \n",
        "label_counting_sorted = label_counter.most_common()\n",
        "\n",
        "NUM_TRAINING_IMAGES = sum([x[1] for x in label_counting_sorted])\n",
        "print(\"number of examples in the original training dataset: {}\".format(NUM_TRAINING_IMAGES))\n",
        "\n",
        "print(\"labels in the original training dataset, sorted by occurrence\")\n",
        "label_counting_sorted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cKsdubraCzU"
      },
      "source": [
        "Define the repition size for oversampling classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3xsTd_naBnx"
      },
      "outputs": [],
      "source": [
        "# We want each class occur at least (approximately) `TARGET_MIN_COUNTING` times\n",
        "TARGET_MIN_COUNTING = 400000\n",
        "\n",
        "def get_num_of_repetition_for_class(class_id):\n",
        "    \n",
        "    counting = label_counter[class_id]\n",
        "    if counting >= TARGET_MIN_COUNTING:\n",
        "        return 1.0\n",
        "    \n",
        "    num_to_repeat = TARGET_MIN_COUNTING / counting\n",
        "    \n",
        "    return num_to_repeat\n",
        "\n",
        "numbers_of_repetition_for_classes = {class_id: get_num_of_repetition_for_class(class_id) for class_id in range(4)}\n",
        "\n",
        "print(\"number of repetitions for each class (if > 1)\")\n",
        "{k: v for k, v in sorted(numbers_of_repetition_for_classes.items(), key=lambda item: item[1], reverse=True) if v > 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hiZpLKJaHsA"
      },
      "outputs": [],
      "source": [
        "# This will be called later in `get_training_dataset_with_oversample()`\n",
        "\n",
        "keys_tensor = tf.constant([k for k in numbers_of_repetition_for_classes])\n",
        "vals_tensor = tf.constant([numbers_of_repetition_for_classes[k] for k in numbers_of_repetition_for_classes])\n",
        "table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), -1)\n",
        "\n",
        "def get_num_of_repetition_for_example(training_example):\n",
        "    \n",
        "    _, label = training_example\n",
        "    \n",
        "    num_to_repeat = table.lookup(label)\n",
        "    num_to_repeat_integral = tf.cast(int(num_to_repeat), tf.float32)\n",
        "    residue = num_to_repeat - num_to_repeat_integral\n",
        "    \n",
        "    num_to_repeat = num_to_repeat_integral + tf.cast(tf.random.uniform(shape=()) <= residue, tf.float32)\n",
        "    \n",
        "    return tf.cast(num_to_repeat, tf.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55yjaveVaK6p"
      },
      "outputs": [],
      "source": [
        "def get_training_dataset_with_oversample(repeat_dataset=True, oversample=False):\n",
        "\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "\n",
        "    if oversample:\n",
        "        dataset = dataset.flat_map(lambda image, label: tf.data.Dataset.from_tensors((image, label)).repeat(get_num_of_repetition_for_example((image, label))))\n",
        "\n",
        "    if repeat_dataset:\n",
        "        dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    \n",
        "    dataset = dataset.shuffle(20000)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    \n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GDjDMn5GeNb"
      },
      "source": [
        "# Dataset visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqZJ0otTGeNb"
      },
      "outputs": [],
      "source": [
        "# data dump\n",
        "# This will take approx 1 minutes to shuffle the data\n",
        "\n",
        "print(\"Loading... Please wait for data to shuffle\")\n",
        "print(\"Training data shapes:\")\n",
        "for image, label in get_training_dataset().take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "    print(\"Training data label examples:\", label.numpy())\n",
        "    print(\"Validation data shapes:\")\n",
        "for image, label in get_validation_dataset().take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "    print(\"Validation data label examples:\", label.numpy())\n",
        "    print(\"Test data shapes:\")\n",
        "for image, idnum in get_test_dataset().take(3):\n",
        "    print(image.numpy().shape, idnum.numpy().shape)\n",
        "    print(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9fAiaSYGeNb"
      },
      "outputs": [],
      "source": [
        "# Peek at training data\n",
        "training_dataset = get_training_dataset()\n",
        "training_dataset = training_dataset.unbatch().batch(20)\n",
        "train_batch = iter(training_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_7YfZbNGeNc"
      },
      "outputs": [],
      "source": [
        "# run this cell again for next set of images\n",
        "# This will take a little bit to load\n",
        "display_batch_of_images(next(train_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8iwzsqtGeNc"
      },
      "outputs": [],
      "source": [
        "# # peer at test data\n",
        "# test_dataset = get_test_dataset()\n",
        "# test_dataset = test_dataset.unbatch().batch(20)\n",
        "# test_batch = iter(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcL0CLJRGeNc"
      },
      "outputs": [],
      "source": [
        "# # run this cell again for next set of images\n",
        "# # This will take a little bit to load\n",
        "# display_batch_of_images(next(test_batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2cjlRp6GeNd"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ_LZVufGeNd"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "def create_model():\n",
        "  # for pretrained, freeze model set classes to 1000 then change the classes to 4 manually\n",
        "  base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "  # Let's take a look to see how many layers are in the base model\n",
        "  print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "  # Fine-tune from this layer onwards\n",
        "  fine_tune_at = FINE_TUNE_BUFFER\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # for layer in base_model.layers:\n",
        "  #   if hasattr(layer, 'kernel_regularizer'):\n",
        "  #       layer.kernel_regularizer= tf.keras.regularizers.l2(0.001)\n",
        "\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  # dropout_layer = tf.keras.layers.Dropout(0.2)(global_average_layer)\n",
        "  prediction_layer = tf.keras.layers.Dense(4, activation = 'softmax')\n",
        "  \n",
        "  # define new model\n",
        "  model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    global_average_layer,\n",
        "    tf.keras.layers.Dropout(DROPOUT_VALUE),\n",
        "    prediction_layer\n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApfFgMhSLUVG"
      },
      "outputs": [],
      "source": [
        "lr = tf.keras.experimental.CosineDecay(BASE_LR, STEPS_PER_EPOCH * EPOCHS) # cosine learning decay\n",
        "\n",
        "with strategy.scope():\n",
        "    #img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.xception.preprocess_input(tf.cast(data, tf.float32)), input_shape=[*IMAGE_SIZE, 3])\n",
        "    #pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False)\n",
        "    \n",
        "    # img_adjust_layer = tf.keras.layers.Lambda(lambda data: tf.keras.applications.vgg16.preprocess_input(tf.cast(data, tf.float32)), input_shape=[*IMAGE_SIZE, 3])\n",
        "\n",
        "    model = create_model()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr) #adam optimizer\n",
        "        \n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    # predict True positives/total images\n",
        "    metrics=['accuracy'],\n",
        "    # NEW on TPU in TensorFlow 24: sending multiple batches to the TPU at once saves communications\n",
        "    # overheads and allows the XLA compiler to unroll the loop on TPU and optimize hardware utilization.\n",
        "    steps_per_execution=16\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "parameters = model.count_params()\n",
        "print(parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va58P25PGeNe"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWwf6UfVGeNe"
      },
      "outputs": [],
      "source": [
        "print(\"Loading... Please wait for data to shuffle\")\n",
        "\n",
        "history = model.fit(get_training_dataset_with_oversample(repeat_dataset=True, oversample=True), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\n",
        "                    validation_data=get_validation_dataset(), validation_steps=VALIDATION_STEPS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6ZcpbPpZ1NR"
      },
      "outputs": [],
      "source": [
        "# model_location = f\"/content/drive/MyDrive/CV_Research/TPU-Run-3/Models/Project1_Final_Model_V2\"\n",
        "\n",
        "\n",
        "# model.load_weights(model_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dDZsfCOWmfP"
      },
      "source": [
        "## Save Model (to google drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP9OivKmWo0p"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "from datetime import datetime\n",
        "\n",
        "current_time = now = datetime.now()\n",
        "\n",
        "model_location = f\"/content/drive/MyDrive/CV_Research/StairNet/Run 1/Models/StairNet_18\"\n",
        "\n",
        "model.save(model_location, save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h7iP7-bGeNe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (10, 5)\n",
        "data = pd.DataFrame(history.history)\n",
        "metrics = ['loss', 'accuracy']\n",
        "\n",
        "metrics_array = []\n",
        "\n",
        "for metric in metrics:\n",
        "    data[[f'{metric}',f'val_{metric}']].plot()\n",
        "\n",
        "plot_location = f\"/content/drive/MyDrive/CV_Research/StairNet/Run 1/Plots/StairNet_18.jpg\"\n",
        "plt.savefig(plot_location)\n",
        "\n",
        "csv_location = f\"/content/drive/MyDrive/CV_Research/StairNet/Run 1/CSV/StairNet_18.csv\"\n",
        "\n",
        "results_df = pd.DataFrame(history.history)\n",
        "print(results_df)\n",
        "results_df.to_csv(csv_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU2cn8DQGeNe"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_03v2GkbGeNf"
      },
      "outputs": [],
      "source": [
        "cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy() # get everything as one batch\n",
        "cm_probabilities = model.predict(images_ds, steps=VALIDATION_STEPS)\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n",
        "print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQjd5NfbGeNf"
      },
      "outputs": [],
      "source": [
        "cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\n",
        "# score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='weighted')\n",
        "# precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='weighted')\n",
        "# recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='weighted')\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n",
        "accuracy = accuracy_score(cm_correct_labels, cm_predictions)\n",
        "# display_confusion_matrix(cmat, score, precision, recall)\n",
        "print('accuracy: {:.5f}, f1 score: {:.5f}, precision: {:.5f}, recall: {:.5f}'.format(accuracy, score, precision, recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_1yMXBiEvcH"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cmat, annot=True, fmt='.2%', cmap='Blues')\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Normalized Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['IS', 'IS-LG', 'LG', 'LG-IS']); ax.yaxis.set_ticklabels(['IS', 'IS-LG', 'LG', 'LG-IS']);\n",
        "\n",
        "plot_location = f\"/content/drive/MyDrive/CV_Research//StairNet/Run 1/CM/StairNet_18.jpg\"\n",
        "plt.savefig(plot_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tzjmdRSGeNf"
      },
      "source": [
        "# Final Test Predictions (Comment out until final model is generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mysaIZO6GeNg"
      },
      "outputs": [],
      "source": [
        "cmdataset = get_test_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n",
        "images_ds = cmdataset.map(lambda image, label: image)\n",
        "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
        "cm_correct_labels = next(iter(labels_ds.batch(NUM_TEST_IMAGES))).numpy() # get everything as one batch\n",
        "cm_probabilities = model.predict(images_ds, steps=TEST_STEPS)\n",
        "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
        "print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n",
        "print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz0vN6SXxDBa"
      },
      "outputs": [],
      "source": [
        "cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\n",
        "# score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='weighted')\n",
        "# precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='weighted')\n",
        "# recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='weighted')\n",
        "cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n",
        "accuracy = accuracy_score(cm_correct_labels, cm_predictions)\n",
        "# display_confusion_matrix(cmat, score, precision, recall)\n",
        "print('accuracy: {:.5f}, f1 score: {:.5f}, precision: {:.5f}, recall: {:.5f}'.format(accuracy, score, precision, recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjUerjadbqjO"
      },
      "outputs": [],
      "source": [
        "# cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\n",
        "# score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "# precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "# recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n",
        "# cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n",
        "# accuracy = accuracy_score(cm_correct_labels, cm_predictions)\n",
        "# # display_confusion_matrix(cmat, score, precision, recall)\n",
        "# print('accuracy: {:.3f}, f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(accuracy, score, precision, recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22qix_7-xEtv"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cmat, annot=True, fmt='.2%', cmap='Blues')\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Normalized Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['IS', 'IS-LG', 'LG', 'LG-IS']); ax.yaxis.set_ticklabels(['IS', 'IS-LG', 'LG', 'LG-IS']);\n",
        "\n",
        "plot_location = f\"/content/drive/MyDrive/CV_Research//StairNet/Run 1/CM/StairNet_18_Test.jpg\"\n",
        "plt.savefig(plot_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vttDtPXGeNg"
      },
      "source": [
        "# Visual validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHVvbZZ8GeNg"
      },
      "outputs": [],
      "source": [
        "# dataset = get_validation_dataset()\n",
        "# dataset = dataset.unbatch().batch(20)\n",
        "# batch = iter(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El_MuY1uGeNg"
      },
      "outputs": [],
      "source": [
        "# # run this cell again for next set of images\n",
        "# images, labels = next(batch)\n",
        "# probabilities = model.predict(tf.cast(images, tf.float32))\n",
        "# predictions = np.argmax(probabilities, axis=-1)\n",
        "# display_batch_of_images((images, labels), predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTpZ8UiyGeNh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "StairNet_18.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}